{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4291daa-e8ea-4475-a1bf-96833fa13a82",
   "metadata": {},
   "source": [
    "# RNNs and sequence processing\n",
    "\n",
    "## Tutorial and homework 1: Sentiment Analysis\n",
    "\n",
    "We will look at a simple example of sequence processing in sentiment analysis. Sentiment analysis is used to determine the emotion in a text. \n",
    "\n",
    "We will use a data set from IMDB consisting of movie reviews and are only interested if they are positive or negative (http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "In addition to the libraries installed last time, we will also neet torchtext and datasets: \n",
    "\n",
    "pip install torchtext\n",
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "ffb3bca6-8711-4bd1-a54c-eae0a4966c19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:07.996040Z",
     "start_time": "2025-09-28T16:47:07.993369Z"
    }
   },
   "source": [
    "import collections\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import tqdm\n",
    "import torchtext.data\n",
    "import torchtext.vocab"
   ],
   "outputs": [],
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "id": "f4f9cb30-946b-45b8-9531-9984249cfa3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:08.002609Z",
     "start_time": "2025-09-28T16:47:08.001072Z"
    }
   },
   "source": [
    "# should be version 0.18.0\n",
    "print(torchtext.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.2\n"
     ]
    }
   ],
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "id": "71c9077d-ddea-4a6c-9a65-4f45814e2295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:08.014211Z",
     "start_time": "2025-09-28T16:47:08.012171Z"
    }
   },
   "source": [
    "seed = 1234\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": [],
   "execution_count": 213
  },
  {
   "cell_type": "markdown",
   "id": "d5969ca5-546f-4b87-b0fe-59caa38f2e80",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing the IMDb Dataset\n",
    "\n",
    "Weâ€™ll use datasets to load and preprocess the IMDb dataset (it is also available from torchtext)\n",
    "- TorchText makes it easy to handle text data, including tokenization, padding, and batch generation.\n",
    "- IMDB Dataset consists of movie reviews labeled as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "id": "cbb8a673-db3f-4a5b-bb24-35d98aafe6af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:09.975939Z",
     "start_time": "2025-09-28T16:47:08.023444Z"
    }
   },
   "source": [
    "train_data, test_data = datasets.load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "train_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 214
  },
  {
   "cell_type": "markdown",
   "id": "f344b68f-b677-494c-9cae-bf066f0d401a",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "We will use a tokinizer to split the sentences in words. This tokenizer will normalize english text first and then extract the words."
   ]
  },
  {
   "cell_type": "code",
   "id": "4645d12b-a223-433f-94be-5dfb6f6db617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:10.008153Z",
     "start_time": "2025-09-28T16:47:10.006674Z"
    }
   },
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")"
   ],
   "outputs": [],
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "id": "d5a90d26-54cc-4020-ac4c-7a454d84723b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:10.026106Z",
     "start_time": "2025-09-28T16:47:10.024544Z"
    }
   },
   "source": [
    "def tokenize_example(example, tokenizer, max_length):\n",
    "    tokens = tokenizer(example[\"text\"])[:max_length]\n",
    "    length = len(tokens)\n",
    "    return {\"tokens\": tokens, \"length\": length}"
   ],
   "outputs": [],
   "execution_count": 216
  },
  {
   "cell_type": "markdown",
   "id": "60ffea7b-20d1-41e4-a3f9-e0e2283d6079",
   "metadata": {},
   "source": [
    "### Token sequence\n",
    "This will transfer the input data into sequences of words of a maximal length. While the model does not require the sequences to have the same length, it is needed for batch processing later.\n",
    "\n",
    "We then split the data sets."
   ]
  },
  {
   "cell_type": "code",
   "id": "e4ddde67-d79b-4dab-b7e1-b0b1d07b5e03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:10.037756Z",
     "start_time": "2025-09-28T16:47:10.029976Z"
    }
   },
   "source": [
    "max_length = 256\n",
    "\n",
    "train_data = train_data.map(\n",
    "    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",
    ")\n",
    "test_data = test_data.map(\n",
    "    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 217
  },
  {
   "cell_type": "code",
   "id": "2244709b-2255-409a-ad96-812d7dcf6230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:10.044867Z",
     "start_time": "2025-09-28T16:47:10.041024Z"
    }
   },
   "source": [
    "test_size = 0.25\n",
    "\n",
    "train_valid_data = train_data.train_test_split(test_size=test_size)\n",
    "train_data = train_valid_data[\"train\"]\n",
    "valid_data = train_valid_data[\"test\"]"
   ],
   "outputs": [],
   "execution_count": 218
  },
  {
   "cell_type": "markdown",
   "id": "2d8c86b2-84da-485f-8aea-4320a151ce36",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "\n",
    "Next we build the vocabulary of all words in the set and add two special \"words\" for unknown and padding."
   ]
  },
  {
   "cell_type": "code",
   "id": "da1ac450-e307-4c44-91c1-1355a12c91d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:11.041556Z",
     "start_time": "2025-09-28T16:47:10.046896Z"
    }
   },
   "source": [
    "min_freq = 5\n",
    "special_tokens = [\"<unk>\", \"<pad>\"]\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "unk_index = vocab[\"<unk>\"]\n",
    "pad_index = vocab[\"<pad>\"]\n",
    "\n",
    "vocab.set_default_index(unk_index)"
   ],
   "outputs": [],
   "execution_count": 219
  },
  {
   "cell_type": "code",
   "id": "6a89ad0c-521d-406c-b657-2b457795b73a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:11.055661Z",
     "start_time": "2025-09-28T16:47:11.054240Z"
    }
   },
   "source": [
    "def numericalize_example(example, vocab):\n",
    "    ids = vocab.lookup_indices(example[\"tokens\"])\n",
    "    return {\"ids\": ids}"
   ],
   "outputs": [],
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "id": "ac783c13-40ef-49e5-873d-2030eceb5429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:11.116324Z",
     "start_time": "2025-09-28T16:47:11.064696Z"
    }
   },
   "source": [
    "train_data = train_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})"
   ],
   "outputs": [],
   "execution_count": 221
  },
  {
   "cell_type": "code",
   "id": "8323344c-4c4b-4970-b503-85bbec3bcfb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:11.124454Z",
     "start_time": "2025-09-28T16:47:11.122089Z"
    }
   },
   "source": [
    "train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n",
    "valid_data = valid_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n",
    "test_data = test_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])"
   ],
   "outputs": [],
   "execution_count": 222
  },
  {
   "cell_type": "code",
   "id": "4cfc2446-cff7-4f44-bc23-08570a39ec31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:11.195356Z",
     "start_time": "2025-09-28T16:47:11.130482Z"
    }
   },
   "source": "train_data[0]",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[223]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrain_data\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/arrow_dataset.py:2782\u001B[39m, in \u001B[36mDataset.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   2780\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[32m   2781\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2782\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/arrow_dataset.py:2767\u001B[39m, in \u001B[36mDataset._getitem\u001B[39m\u001B[34m(self, key, **kwargs)\u001B[39m\n\u001B[32m   2765\u001B[39m formatter = get_formatter(format_type, features=\u001B[38;5;28mself\u001B[39m._info.features, **format_kwargs)\n\u001B[32m   2766\u001B[39m pa_subtable = query_table(\u001B[38;5;28mself\u001B[39m._data, key, indices=\u001B[38;5;28mself\u001B[39m._indices)\n\u001B[32m-> \u001B[39m\u001B[32m2767\u001B[39m formatted_output = \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2768\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m=\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[32m   2769\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2770\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/formatting/formatting.py:666\u001B[39m, in \u001B[36mformat_table\u001B[39m\u001B[34m(table, key, formatter, format_columns, output_all_columns)\u001B[39m\n\u001B[32m    664\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    665\u001B[39m     pa_table_to_format = pa_table.drop(col \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m pa_table.column_names \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m format_columns)\n\u001B[32m--> \u001B[39m\u001B[32m666\u001B[39m     formatted_output = \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table_to_format\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    667\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m output_all_columns:\n\u001B[32m    668\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(formatted_output, MutableMapping):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/formatting/formatting.py:411\u001B[39m, in \u001B[36mFormatter.__call__\u001B[39m\u001B[34m(self, pa_table, query_type)\u001B[39m\n\u001B[32m    409\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa.Table, query_type: \u001B[38;5;28mstr\u001B[39m) -> Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001B[32m    410\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m query_type == \u001B[33m\"\u001B[39m\u001B[33mrow\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m411\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mformat_row\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    412\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m query_type == \u001B[33m\"\u001B[39m\u001B[33mcolumn\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    413\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.format_column(pa_table)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/formatting/torch_formatter.py:109\u001B[39m, in \u001B[36mTorchFormatter.format_row\u001B[39m\u001B[34m(self, pa_table)\u001B[39m\n\u001B[32m    107\u001B[39m row = \u001B[38;5;28mself\u001B[39m.numpy_arrow_extractor().extract_row(pa_table)\n\u001B[32m    108\u001B[39m row = \u001B[38;5;28mself\u001B[39m.python_features_decoder.decode_row(row)\n\u001B[32m--> \u001B[39m\u001B[32m109\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrecursive_tensorize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/formatting/torch_formatter.py:104\u001B[39m, in \u001B[36mTorchFormatter.recursive_tensorize\u001B[39m\u001B[34m(self, data_struct)\u001B[39m\n\u001B[32m    103\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrecursive_tensorize\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_struct: \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m104\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_recursive_tensorize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_list\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/utils/py_utils.py:511\u001B[39m, in \u001B[36mmap_nested\u001B[39m\u001B[34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001B[39m\n\u001B[32m    509\u001B[39m         batch_size = \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) // num_proc + \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) % num_proc > \u001B[32m0\u001B[39m), \u001B[32m1\u001B[39m)\n\u001B[32m    510\u001B[39m     iterable = \u001B[38;5;28mlist\u001B[39m(iter_batched(iterable, batch_size))\n\u001B[32m--> \u001B[39m\u001B[32m511\u001B[39m mapped = \u001B[43m[\u001B[49m\n\u001B[32m    512\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_single_map_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    513\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhf_tqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdisable_tqdm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    514\u001B[39m \u001B[43m\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    515\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[32m    516\u001B[39m     mapped = [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m mapped_batch \u001B[38;5;129;01min\u001B[39;00m mapped \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m mapped_batch]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/utils/py_utils.py:512\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    509\u001B[39m         batch_size = \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) // num_proc + \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) % num_proc > \u001B[32m0\u001B[39m), \u001B[32m1\u001B[39m)\n\u001B[32m    510\u001B[39m     iterable = \u001B[38;5;28mlist\u001B[39m(iter_batched(iterable, batch_size))\n\u001B[32m    511\u001B[39m mapped = [\n\u001B[32m--> \u001B[39m\u001B[32m512\u001B[39m     \u001B[43m_single_map_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    513\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m hf_tqdm(iterable, disable=disable_tqdm, desc=desc)\n\u001B[32m    514\u001B[39m ]\n\u001B[32m    515\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[32m    516\u001B[39m     mapped = [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m mapped_batch \u001B[38;5;129;01min\u001B[39;00m mapped \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m mapped_batch]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/utils/py_utils.py:373\u001B[39m, in \u001B[36m_single_map_nested\u001B[39m\u001B[34m(args)\u001B[39m\n\u001B[32m    371\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m function([data_struct])[\u001B[32m0\u001B[39m]\n\u001B[32m    372\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m373\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    374\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    375\u001B[39m     batched\n\u001B[32m    376\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mdict\u001B[39m)\n\u001B[32m    377\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, types)\n\u001B[32m    378\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, (\u001B[38;5;28mdict\u001B[39m, types)) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m data_struct)\n\u001B[32m    379\u001B[39m ):\n\u001B[32m    380\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m iter_batched(data_struct, batch_size) \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m function(batch)]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/formatting/torch_formatter.py:101\u001B[39m, in \u001B[36mTorchFormatter._recursive_tensorize\u001B[39m\u001B[34m(self, data_struct)\u001B[39m\n\u001B[32m     99\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[32m    100\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._consolidate([\u001B[38;5;28mself\u001B[39m.recursive_tensorize(substruct) \u001B[38;5;28;01mfor\u001B[39;00m substruct \u001B[38;5;129;01min\u001B[39;00m data_struct])\n\u001B[32m--> \u001B[39m\u001B[32m101\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_tensorize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/datasets/formatting/torch_formatter.py:87\u001B[39m, in \u001B[36mTorchFormatter._tensorize\u001B[39m\u001B[34m(self, value)\u001B[39m\n\u001B[32m     84\u001B[39m         value._hf_bridge_out = to_torch\n\u001B[32m     85\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mdefault_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtorch_tensor_kwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: len() of unsized object"
     ]
    }
   ],
   "execution_count": 223
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "463878e6e9fc6e7c"
  },
  {
   "cell_type": "markdown",
   "id": "512352f1-7b44-4d98-92b3-4d3bc1f3a89c",
   "metadata": {},
   "source": [
    "### Creating Batches\n",
    "\n",
    "Next we create batches out of the data with the same length and store the indices, actual length and label in the batch."
   ]
  },
  {
   "cell_type": "code",
   "id": "56911a3d-9224-45e4-8885-b802954e274e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:19.599737Z",
     "start_time": "2025-09-28T16:47:19.597268Z"
    }
   },
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = [i[\"ids\"] for i in batch]\n",
    "        batch_ids = nn.utils.rnn.pad_sequence(\n",
    "            batch_ids, padding_value=pad_index, batch_first=True\n",
    "        )\n",
    "        batch_length = [i[\"length\"] for i in batch]\n",
    "        batch_length = torch.stack(batch_length)\n",
    "        batch_label = [i[\"label\"] for i in batch]\n",
    "        batch_label = torch.stack(batch_label)\n",
    "        batch = {\"ids\": batch_ids, \"length\": batch_length, \"label\": batch_label}\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ],
   "outputs": [],
   "execution_count": 224
  },
  {
   "cell_type": "code",
   "id": "fc932aea-0a2d-4a22-a655-59bbe048027b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:23.150440Z",
     "start_time": "2025-09-28T16:47:23.147933Z"
    }
   },
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ],
   "outputs": [],
   "execution_count": 225
  },
  {
   "cell_type": "code",
   "id": "a1293e9a-2682-4cd8-9bf2-9bebcfa9edf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:27.098383Z",
     "start_time": "2025-09-28T16:47:27.095462Z"
    }
   },
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ],
   "outputs": [],
   "execution_count": 226
  },
  {
   "cell_type": "markdown",
   "id": "ff3247b2-ec26-43ee-9506-83676edff0ed",
   "metadata": {},
   "source": [
    "### RNN Model\n",
    "\n",
    "Now we can build a model, we will use a RNN Model first. It includes\n",
    "\n",
    "- Embedding Layer: Turns words into dense vectors.\n",
    "- RNN Layer: A simple recurrent layer to capture sequence information.\n",
    "- Fully Connected Layer: To classify the output."
   ]
  },
  {
   "cell_type": "code",
   "id": "0ec9c695-3f42-474d-952b-8e56cfa1d299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:47:34.857511Z",
     "start_time": "2025-09-28T16:47:34.853382Z"
    }
   },
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, \n",
    "                          bidirectional=bidirectional, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, ids, length):\n",
    "        # ids = [batch size, seq len]\n",
    "        # length = [batch size]\n",
    "        embedded = self.dropout(self.embedding(ids))\n",
    "        # embedded = [batch size, seq len, embedding dim]\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, length, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_output, hidden = self.rnn(packed_embedded)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "\n",
    "        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        # output = [batch size, seq len, hidden dim * n directions]\n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
    "            # hidden = [batch size, hidden dim * 2]\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1])\n",
    "            # hidden = [batch size, hidden dim]\n",
    "        prediction = self.fc(hidden)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction\n",
    "  "
   ],
   "outputs": [],
   "execution_count": 228
  },
  {
   "cell_type": "code",
   "id": "f04f6041-9a3a-45b2-9f74-096205180508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:49:08.316096Z",
     "start_time": "2025-09-28T16:49:08.245389Z"
    }
   },
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "output_dim = len(train_data.unique(\"label\"))\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5\n",
    "\n",
    "model = RNN(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    n_layers,\n",
    "    bidirectional,\n",
    "    dropout_rate,\n",
    "    pad_index,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 236
  },
  {
   "cell_type": "code",
   "id": "815bd833-5744-4562-8300-a528502b2698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:49:10.566082Z",
     "start_time": "2025-09-28T16:49:10.563430Z"
    }
   },
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,394,102 trainable parameters\n"
     ]
    }
   ],
   "execution_count": 237
  },
  {
   "cell_type": "markdown",
   "id": "7b443ae8-14b2-4d83-b1ed-6f24c0eb41aa",
   "metadata": {},
   "source": [
    "### Pretrained embeddings\n",
    "\n",
    "The model will learn the embeddings too, which is a bit difficult from the limited data. Results will be much better if a pretrained model is used for that.\n",
    "\n",
    "We will use glove (https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "The following code will download and cache the vectors. The data set is quite large so you can also omit this first..."
   ]
  },
  {
   "cell_type": "code",
   "id": "00a7bb71-a00e-48cf-8d5e-3c317c372d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:48:21.023122Z",
     "start_time": "2025-09-28T16:47:45.128442Z"
    }
   },
   "source": [
    "vectors = torchtext.vocab.GloVe()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.840B.300d.zip:   9%|â–‰         | 194M/2.18G [00:35<06:04, 5.44MB/s]     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[230]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m vectors = \u001B[43mtorchtext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m.\u001B[49m\u001B[43mGloVe\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torchtext/vocab/vectors.py:223\u001B[39m, in \u001B[36mGloVe.__init__\u001B[39m\u001B[34m(self, name, dim, **kwargs)\u001B[39m\n\u001B[32m    221\u001B[39m url = \u001B[38;5;28mself\u001B[39m.url[name]\n\u001B[32m    222\u001B[39m name = \u001B[33m\"\u001B[39m\u001B[33mglove.\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33md.txt\u001B[39m\u001B[33m\"\u001B[39m.format(name, \u001B[38;5;28mstr\u001B[39m(dim))\n\u001B[32m--> \u001B[39m\u001B[32m223\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mGloVe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torchtext/vocab/vectors.py:59\u001B[39m, in \u001B[36mVectors.__init__\u001B[39m\u001B[34m(self, name, cache, url, unk_init, max_vectors)\u001B[39m\n\u001B[32m     57\u001B[39m \u001B[38;5;28mself\u001B[39m.dim = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28mself\u001B[39m.unk_init = torch.Tensor.zero_ \u001B[38;5;28;01mif\u001B[39;00m unk_init \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m unk_init\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_vectors\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_vectors\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torchtext/vocab/vectors.py:101\u001B[39m, in \u001B[36mVectors.cache\u001B[39m\u001B[34m(self, name, cache, url, max_vectors)\u001B[39m\n\u001B[32m     99\u001B[39m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# remove the partial zip file\u001B[39;00m\n\u001B[32m    100\u001B[39m             os.remove(dest)\n\u001B[32m--> \u001B[39m\u001B[32m101\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    102\u001B[39m logger.info(\u001B[33m\"\u001B[39m\u001B[33mExtracting vectors into \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m\"\u001B[39m.format(cache))\n\u001B[32m    103\u001B[39m ext = os.path.splitext(dest)[\u001B[32m1\u001B[39m][\u001B[32m1\u001B[39m:]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torchtext/vocab/vectors.py:98\u001B[39m, in \u001B[36mVectors.cache\u001B[39m\u001B[34m(self, name, cache, url, max_vectors)\u001B[39m\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(unit=\u001B[33m\"\u001B[39m\u001B[33mB\u001B[39m\u001B[33m\"\u001B[39m, unit_scale=\u001B[38;5;28;01mTrue\u001B[39;00m, miniters=\u001B[32m1\u001B[39m, desc=dest) \u001B[38;5;28;01mas\u001B[39;00m t:\n\u001B[32m     97\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m98\u001B[39m         \u001B[43murlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreporthook\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreporthook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     99\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# remove the partial zip file\u001B[39;00m\n\u001B[32m    100\u001B[39m         os.remove(dest)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/urllib/request.py:270\u001B[39m, in \u001B[36murlretrieve\u001B[39m\u001B[34m(url, filename, reporthook, data)\u001B[39m\n\u001B[32m    267\u001B[39m     reporthook(blocknum, bs, size)\n\u001B[32m    269\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m270\u001B[39m     block = \u001B[43mfp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    271\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m block:\n\u001B[32m    272\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/http/client.py:473\u001B[39m, in \u001B[36mHTTPResponse.read\u001B[39m\u001B[34m(self, amt)\u001B[39m\n\u001B[32m    470\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.length \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt > \u001B[38;5;28mself\u001B[39m.length:\n\u001B[32m    471\u001B[39m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[32m    472\u001B[39m     amt = \u001B[38;5;28mself\u001B[39m.length\n\u001B[32m--> \u001B[39m\u001B[32m473\u001B[39m s = \u001B[38;5;28mself\u001B[39m.fp.read(amt)\n\u001B[32m    474\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[32m    475\u001B[39m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[32m    476\u001B[39m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[32m    477\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_conn()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/socket.py:718\u001B[39m, in \u001B[36mSocketIO.readinto\u001B[39m\u001B[34m(self, b)\u001B[39m\n\u001B[32m    716\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    717\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m718\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    719\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[32m    720\u001B[39m         \u001B[38;5;28mself\u001B[39m._timeout_occurred = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/ssl.py:1314\u001B[39m, in \u001B[36mSSLSocket.recv_into\u001B[39m\u001B[34m(self, buffer, nbytes, flags)\u001B[39m\n\u001B[32m   1310\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m flags != \u001B[32m0\u001B[39m:\n\u001B[32m   1311\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1312\u001B[39m           \u001B[33m\"\u001B[39m\u001B[33mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m %\n\u001B[32m   1313\u001B[39m           \u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1314\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1315\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1316\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/ssl.py:1166\u001B[39m, in \u001B[36mSSLSocket.read\u001B[39m\u001B[34m(self, len, buffer)\u001B[39m\n\u001B[32m   1164\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1165\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1166\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sslobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1167\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1168\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sslobj.read(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 230
  },
  {
   "cell_type": "code",
   "id": "464211c9-4db4-4e77-8455-70f83212b0ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:49:21.276503Z",
     "start_time": "2025-09-28T16:49:21.260212Z"
    }
   },
   "source": [
    "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n",
    "model.embedding.weight.data = pretrained_embedding"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[238]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m pretrained_embedding = \u001B[43mvectors\u001B[49m.get_vecs_by_tokens(vocab.get_itos())\n\u001B[32m      2\u001B[39m model.embedding.weight.data = pretrained_embedding\n",
      "\u001B[31mNameError\u001B[39m: name 'vectors' is not defined"
     ]
    }
   ],
   "execution_count": 238
  },
  {
   "cell_type": "markdown",
   "id": "c5f737cf-b571-4e17-a6db-e1807380c98c",
   "metadata": {},
   "source": [
    "### Train function\n",
    "Next we need the functions to train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "id": "13e87cdf-4ee3-4afd-82aa-7f1f362c68f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:49:22.653542Z",
     "start_time": "2025-09-28T16:49:22.647885Z"
    }
   },
   "source": [
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    for batch in tqdm.tqdm(dataloader, desc=\"training...\"):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        length = batch[\"length\"]\n",
    "        label = batch[\"label\"].to(device)\n",
    "        prediction = model(ids, length)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)\n",
    "\n",
    "def evaluate(dataloader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(dataloader, desc=\"evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            length = batch[\"length\"]\n",
    "            label = batch[\"label\"].to(device)\n",
    "            prediction = model(ids, length)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)\n",
    "\n",
    "# calculate the accuracy, we could also use the metrics classes as in the last exercise\n",
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy\n"
   ],
   "outputs": [],
   "execution_count": 239
  },
  {
   "cell_type": "markdown",
   "id": "eb4656ed-a0c0-4ee2-92fa-05149acff513",
   "metadata": {},
   "source": [
    "Construct model and train"
   ]
  },
  {
   "cell_type": "code",
   "id": "9b516650-0708-40ca-a084-28698ab1938b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:49:25.278702Z",
     "start_time": "2025-09-28T16:49:25.026037Z"
    }
   },
   "source": [
    "lr = 5e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'set_guard_fail_hook' from 'torch._dynamo.eval_frame' (/Users/marbetschar/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[240]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m lr = \u001B[32m5e-4\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m optimizer = \u001B[43moptim\u001B[49m\u001B[43m.\u001B[49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m criterion = nn.CrossEntropyLoss()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torch/optim/adam.py:45\u001B[39m, in \u001B[36m__init__\u001B[39m\u001B[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001B[39m\n\u001B[32m     38\u001B[39m \u001B[38;5;28mself\u001B[39m._step_supports_amp_scaling = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     39\u001B[39m \u001B[38;5;66;03m# TODO(crcrpar): [low prec params & their higher prec copy]\u001B[39;00m\n\u001B[32m     40\u001B[39m \u001B[38;5;66;03m# Suppor AMP with FP16/BF16 model params which would need\u001B[39;00m\n\u001B[32m     41\u001B[39m \u001B[38;5;66;03m# higher prec copy of params to do update math in higher prec to\u001B[39;00m\n\u001B[32m     42\u001B[39m \u001B[38;5;66;03m# alleviate the loss of information.\u001B[39;00m\n\u001B[32m     43\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\n\u001B[32m     44\u001B[39m     p.is_cuda \u001B[38;5;129;01mand\u001B[39;00m torch.is_floating_point(p)\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m pg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.param_groups \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m pg[\u001B[33m'\u001B[39m\u001B[33mparams\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     46\u001B[39m ):\n\u001B[32m     47\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33m`fused=True` requires all the params to be CUDA, floating point Tensor\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m foreach:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torch/optim/optimizer.py:278\u001B[39m, in \u001B[36m__init__\u001B[39m\u001B[34m(self, params, defaults)\u001B[39m\n\u001B[32m    275\u001B[39m             args, kwargs = result\n\u001B[32m    276\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    277\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m278\u001B[39m                                \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    280\u001B[39m out = func(*args, **kwargs)\n\u001B[32m    281\u001B[39m \u001B[38;5;28mself\u001B[39m._optimizer_step_code()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torch/_compile.py:22\u001B[39m, in \u001B[36minner\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torch/_dynamo/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbackends\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mregistry\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m list_backends, register_backend\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconvert_frame\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m replay\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:27\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01meval_frame\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m always_optimize_code_objects, skip_code, TorchPatcher\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     19\u001B[39m     augment_exc_message,\n\u001B[32m     20\u001B[39m     BackendCompilerFailed,\n\u001B[32m   (...)\u001B[39m\u001B[32m     25\u001B[39m     Unsupported,\n\u001B[32m     26\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mguards\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CheckFunctionManager, GuardedCode\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mhooks\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Hooks\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01moutput_graph\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m OutputGraph\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torch/_dynamo/guards.py:26\u001B[39m\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexperimental\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msymbolic_shapes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SYMPY_INTERP\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config, convert_frame, mutation_guard\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01meval_frame\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m set_guard_error_hook, set_guard_fail_hook\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m unimplemented\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtypes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GuardedCode, GuardFail, GuardFn  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'set_guard_fail_hook' from 'torch._dynamo.eval_frame' (/Users/marbetschar/miniconda3/envs/ZHAW-Advanced-Deep-Learning-Python311/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py)"
     ]
    }
   ],
   "execution_count": 240
  },
  {
   "cell_type": "code",
   "id": "49c115c9-fd62-4a1d-99e4-dd183c7c43b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:49:37.902547Z",
     "start_time": "2025-09-28T16:49:37.840489Z"
    }
   },
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        # test if it worked\n",
    "        x = torch.ones(1, device=device)\n",
    "        print('Using CUDA device')\n",
    "\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        x = torch.ones(1, device=device)\n",
    "        print('Using MPS device')\n",
    "    else:\n",
    "        print('Using CPU')\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "device = get_device()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n"
     ]
    }
   ],
   "execution_count": 241
  },
  {
   "cell_type": "code",
   "id": "d3eedbe0-9db9-424c-97e6-11ce731f3f53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:49:39.575797Z",
     "start_time": "2025-09-28T16:49:39.524420Z"
    }
   },
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[242]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m model = model.to(device)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m criterion = \u001B[43mcriterion\u001B[49m.to(device)\n",
      "\u001B[31mNameError\u001B[39m: name 'criterion' is not defined"
     ]
    }
   ],
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "id": "127e8747-2c7e-4a0c-a01c-63d5d0e3ceb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T16:49:44.232034Z",
     "start_time": "2025-09-28T16:49:44.212392Z"
    }
   },
   "source": [
    "n_epochs = 10\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "metrics = collections.defaultdict(list)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(\n",
    "        train_data_loader, model, criterion, optimizer, device\n",
    "    )\n",
    "    valid_loss, valid_acc = evaluate(valid_data_loader, model, criterion, device)\n",
    "    metrics[\"train_losses\"].append(train_loss)\n",
    "    metrics[\"train_accs\"].append(train_acc)\n",
    "    metrics[\"valid_losses\"].append(valid_loss)\n",
    "    metrics[\"valid_accs\"].append(valid_acc)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"lstm.pt\")\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    print(f\"train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}\")\n",
    "    print(f\"valid_loss: {valid_loss:.3f}, valid_acc: {valid_acc:.3f}\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[243]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      4\u001B[39m metrics = collections.defaultdict(\u001B[38;5;28mlist\u001B[39m)\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[32m      7\u001B[39m     train_loss, train_acc = train(\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m         train_data_loader, model, \u001B[43mcriterion\u001B[49m, optimizer, device\n\u001B[32m      9\u001B[39m     )\n\u001B[32m     10\u001B[39m     valid_loss, valid_acc = evaluate(valid_data_loader, model, criterion, device)\n\u001B[32m     11\u001B[39m     metrics[\u001B[33m\"\u001B[39m\u001B[33mtrain_losses\u001B[39m\u001B[33m\"\u001B[39m].append(train_loss)\n",
      "\u001B[31mNameError\u001B[39m: name 'criterion' is not defined"
     ]
    }
   ],
   "execution_count": 243
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c406868-19ba-4f98-b63e-8da9e4615d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73619b-bd02-45e8-a118-5e24949f30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(metrics[\"train_losses\"], label=\"train loss\")\n",
    "ax.plot(metrics[\"valid_losses\"], label=\"valid loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_xticks(range(n_epochs))\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d253c2-2468-44c3-a19a-b2f16218302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(metrics[\"train_accs\"], label=\"train accuracy\")\n",
    "ax.plot(metrics[\"valid_accs\"], label=\"valid accuracy\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_xticks(range(n_epochs))\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef296c-4c6c-4476-b588-061fd955bc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ff282-e43d-4b8a-aadb-70f68889bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, vocab, device):\n",
    "    tokens = tokenizer(text)\n",
    "    ids = vocab.lookup_indices(tokens)\n",
    "    length = torch.LongTensor([len(ids)])\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor, length).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_class = prediction.argmax(dim=-1).item()\n",
    "    predicted_probability = probability[predicted_class].item()\n",
    "    return predicted_class, predicted_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06318769-b141-4687-8eea-295a94748f8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21eac8-0af8-4f7a-92b1-a79527efd3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, vocab, device):\n",
    "    tokens = tokenizer(text)\n",
    "    ids = vocab.lookup_indices(tokens)\n",
    "    length = torch.LongTensor([len(ids)])\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor, length).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_class = prediction.argmax(dim=-1).item()\n",
    "    predicted_probability = probability[predicted_class].item()\n",
    "    return predicted_class, predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8fc23a-b96e-4073-bbea-9198e5ec3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This film is terrible!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43b194-c04a-41c8-8f15-5cfd4669a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This film is great!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1b32b-1368-48c9-9a3b-24fb4dca7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This film is not terrible, it's great!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4b1e7-ca27-4931-b2e5-430c2b473ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This film is not great, it's terrible!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca8f99-cc9a-4cdc-94ef-1cd5e0c01568",
   "metadata": {},
   "source": [
    "## Exercise 1: LSTM\n",
    "\n",
    "The model should not be bad yet (specially if pretrained embeddings are used). Can you replace the RNN with a LSTM and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeed48d-a061-4475-a01f-eb0503f191f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f39a319-9f6d-4097-9ac9-6cbc253ae73e",
   "metadata": {},
   "source": [
    "## Exercise 2: Attention and Transformer (hard)\n",
    "\n",
    "Even as this is not a seq2seq tasks, it would be possible to use attention and transformer ideas here. For example the encoder part and then just use a more simple decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732dca43-15f0-4962-9d1d-d7738349505e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
